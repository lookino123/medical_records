{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractors\n",
    "import regex as re\n",
    "\n",
    "# Fuzzy matching allows for 1 typo\n",
    "\n",
    "\n",
    "def extract_medical_record(text):\n",
    "    \"\"\"Extracts the medical record number from a given text using regex.\"\"\"\n",
    "    pattern = r\"(?:Medical\\s*Record|Medcal\\s*Record|Medicl\\s*Record|MR){e<=1}\\s*#\\s*:\\s*(\\S+)\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        # Check which group matched (1 or 2)\n",
    "        if match.group(1):\n",
    "            return match.group(1).strip()\n",
    "        else:\n",
    "            return match.group(2).strip()\n",
    "    else:\n",
    "        return None  # Or return \"NA\" if you prefer\n",
    "   \n",
    "def extract_name(text):\n",
    "    \"\"\"Extracts patient name from a given text using regex.\"\"\"\n",
    "    pattern = r\"(?:Patient){e<=1}:\\s*([^,]+)\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None  # Or return \"Unknown\" or \"NA\"\n",
    "\n",
    "def extract_age(text):\n",
    "    \"\"\"Extracts age from a given text using regex patterns.\"\"\"\n",
    "    age_patterns = [\n",
    "        r\"(\\d+)-(?:year|yeer|yer|yar){e<=1}-old\",   # Allow 1 typo in \"year\"\n",
    "        r\"(?:age|ag|aeg|gae){e<=1}\\s*(\\d+)\",        # Allow 1 typo in \"age\"\n",
    "        r\"(\\d+)\\s*(?:years?|yeers?|yrs?|yars?){e<=1}\\s*old\",  # Allow 1 typo in \"years\", \"yrs\"\n",
    "        r\"(\\d+)\\s*(?:years?|yeers?|yrs?|yars?){e<=1}\"         # Allow 1 typo in \"years\", \"yrs\"\n",
    "    ]\n",
    "\n",
    "    age = None\n",
    "\n",
    "    for pattern in age_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE) #added re.IGNORECASE to handle variations in case\n",
    "        if match:\n",
    "            try:\n",
    "                age = int(match.group(1))\n",
    "                break  # Stop after finding the first match\n",
    "            except ValueError:\n",
    "                # Handle cases where the extracted value is not a valid number\n",
    "                pass\n",
    "    return age\n",
    "\n",
    "def extract_gender(text):\n",
    "    \"\"\"Extracts gender from a given text using regex.\"\"\"\n",
    "    pattern = r\"\\b(male|female){e<=1}\\b\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).capitalize()  # Capitalize and return\n",
    "    else:\n",
    "        return \"Unknown\"  # Or return None if you prefer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MR</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>58</td>\n",
       "      <td>male</td>\n",
       "      <td>Arrived for a follow-up appointment complainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5678</td>\n",
       "      <td>Linda Green</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>Chief Complaint: Persistent headaches and ting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9102</td>\n",
       "      <td>Michael Brown</td>\n",
       "      <td>62</td>\n",
       "      <td>male</td>\n",
       "      <td>Follow-up for hypertension and Type 2 Diabetes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MR           Name  Age   Gender  \\\n",
       "0  1234     John Smith   58     male   \n",
       "1  5678    Linda Green   45   female   \n",
       "2  9102  Michael Brown   62     male   \n",
       "\n",
       "                                                note  \n",
       "0  Arrived for a follow-up appointment complainin...  \n",
       "1  Chief Complaint: Persistent headaches and ting...  \n",
       "2  Follow-up for hypertension and Type 2 Diabetes...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extract\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_excel(\"notes.xlsx\") \n",
    "\n",
    "# Extract\n",
    "df['MR']       = df['note'].apply(extract_medical_record)\n",
    "df[\"Name\"]     = df[\"note\"].apply(extract_name)\n",
    "df[\"Gender\"]   = df[\"note\"].apply(extract_gender)\n",
    "df['Age']      = df['note'].apply(extract_age)\n",
    "\n",
    "# Cleanup the note on the assumption \\n are in the right place (this shortens the prompt)\n",
    "df['note'] = df['note'].str.split(\"\\n\", expand=True, n=2).fillna(\"\")[2]\n",
    "\n",
    "# Note, remove new lines\n",
    "df['note'] = df['note'].str.replace(\"\\n\", \" \")\n",
    "\n",
    "# Sort the coulmns\n",
    "df = df[[\"MR\",\"Name\", \"Age\", \"Gender\", \"note\"]]\n",
    "\n",
    "display(df.head(3))\n",
    "\n",
    "df.to_csv(\"checkpoint1.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the medical record JSON\n",
    "\n",
    "json_schema = [\n",
    "    [\"disease\", \"The disease the patient is suffering from\"],\n",
    "    [\"symptoms\", \"The symptoms the patient is experiencing\"],\n",
    "    [\"lab_results\", \"The results of the lab tests\"],\n",
    "    [\"current_medication\", \"The medication the patient is currently taking\"],\n",
    "    [\"current_dosage\", \"The dosage of the current medication\"],\n",
    "    [\"current_frequency\", \"The frequency of  current medication\"],\n",
    "    [\"prescribed_medication\", \"The medication prescribed\"],\n",
    "    [\"prescribed_dosage\", \"The dosage of the prescribed medication\"],\n",
    "    [\"prescribed_frequency\", \"The frequency of the prescribed medication\"],\n",
    "]\n",
    "\n",
    "fields= []\n",
    "decritpion = []\n",
    "for x in json_schema:\n",
    "    fields.append(x[0])\n",
    "    decritpion.append(x[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRY_LOCAL=True\n",
      "env: GPU_ID=1\n",
      "Total Memory: 23.7 GB\n",
      "We can run the model locally on gpu  1\n",
      "env: MODEL=Local\n"
     ]
    }
   ],
   "source": [
    "# Check if you can run the model locally\n",
    "import torch\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "%env TRY_LOCAL=True\n",
    "\n",
    "if os.getenv(\"TRY_LOCAL\") != \"True\":\n",
    "    print(\"If you want to try to run your LLM locally, set TRY_LOCAL to True.\")\n",
    "    print(\"Let's use ChatGPT\")\n",
    "    %env MODEL=ChatGPT\n",
    "elif torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    gpu_id = num_gpus - 1 # Arbitrarity run the model on the last GPU, presumably video is on card 0\n",
    "    %env GPU_ID=$gpu_id\n",
    "    total_memory = torch.cuda.get_device_properties(gpu_id).total_memory \n",
    "    print(f\"Total Memory: {total_memory /(1024**3):.1f} GB\")\n",
    "    if total_memory/(1024**3) > 10:\n",
    "        print(\"We can run the model locally on gpu \", gpu_id)\n",
    "        %env MODEL=Local\n",
    "    else:\n",
    "        print(\"Not enough memory to run the model\")\n",
    "        %env MODEL=ChatGPT\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "    print(\"Let's use ChatGPT\")\n",
    "    %env MODEL=ChatGPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen/Qwen2.5-14B-Instruct on cuda:1\n",
      "Using custom cache directory /mnt/hd1\n",
      "Huggingface authenticated as: lookino \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d47749c10d5493b9ea0ec494bc6e86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load LLM on local GPU\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig,StoppingCriteria, StoppingCriteriaList, pipeline\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if os.environ.get(\"MODEL\", \"\") == 'Local':\n",
    "        \n",
    "    model_id = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "\n",
    "    device_s = \"cuda:\" + os.environ.get(\"GPU_ID\", \"\")\n",
    "    device = device_s if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    print(\"Loading \" + model_id + \" on \" + device)  \n",
    "\n",
    "    directory = \"/mnt/hd1\"\n",
    "    if os.path.isdir(directory):\n",
    "        print(\"Using custom cache directory \" + directory)\n",
    "        custom_cache_dir = \"/mnt/hd1\"\n",
    "    else:\n",
    "        custom_cache_dir = \"/tmp\"\n",
    "\n",
    "    #Hugging face API KEY, check it's there and it is valid\n",
    "    HF_API_KEY = os.getenv(\"HF_API_KEY\")\n",
    "    token = HF_API_KEY\n",
    "\n",
    "    if token is None:\n",
    "        print(\"No Huggingface API key found\")\n",
    "    else:\n",
    "        try:\n",
    "            api = HfApi(token=token)\n",
    "            user_info = api.whoami()\n",
    "            print(f\"Huggingface authenticated as: {user_info['name']} \")\n",
    "        except Exception as e:\n",
    "            print(f\"Invalid API key: {e}\")\n",
    "\n",
    "        # Configure bitsandbytes for 4-bit quantization\n",
    "        quant_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",            # \"nf4\" is a popular choice for quantization\n",
    "            bnb_4bit_use_double_quant=True,         # enables double quantization for improved accuracy\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16   # set compute dtype to bfloat16\n",
    "        )\n",
    "\n",
    "        # Load the tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id, token=token)\n",
    "\n",
    "        class StopOnPeriod(StoppingCriteria):\n",
    "            def __call__(self, input_ids, scores, **kwargs):\n",
    "                # Stop if a period followed by a space appears\n",
    "                return tokenizer.decode(input_ids[0]).endswith(\". \")\n",
    "\n",
    "        stopping_criteria = StoppingCriteriaList([StopOnPeriod()])\n",
    "\n",
    "        # Load the model with 4-bit quantization\n",
    "        my_local_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        token=token,\n",
    "        cache_dir=custom_cache_dir,\n",
    "        quantization_config=quant_config,      \n",
    "        device_map=device,              \n",
    "        torch_dtype=torch.bfloat16            \n",
    "        )\n",
    "else:\n",
    "    print(\"This section is disabled, as we are using ChatGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_local_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n\u001b[32m      3\u001b[39m df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mcheckpoint1.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m pipe = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=\u001b[43mmy_local_model\u001b[49m, stopping_criteria=stopping_criteria, tokenizer=tokenizer,generation_kwargs=\n\u001b[32m      7\u001b[39m                 {\n\u001b[32m      8\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.3\u001b[39m,  \n\u001b[32m      9\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mmax_new_tokens\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m512\u001b[39m,  \n\u001b[32m     10\u001b[39m                 },)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Initialize LangChain LLM with HuggingFacePipeline\u001b[39;00m\n\u001b[32m     13\u001b[39m llm = HuggingFacePipeline(pipeline=pipe,pipeline_kwargs={\u001b[33m\"\u001b[39m\u001b[33mmax_new_tokens\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m512\u001b[39m},)\n",
      "\u001b[31mNameError\u001b[39m: name 'my_local_model' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline  # For local Hugging Face models\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "df_local = pd.read_csv(\"checkpoint1.csv\")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=my_local_model, stopping_criteria=stopping_criteria, tokenizer=tokenizer,generation_kwargs=\n",
    "                {\n",
    "                    \"temperature\": 0.3,  \n",
    "                    \"max_new_tokens\": 512,  \n",
    "                },)\n",
    "\n",
    "# Initialize LangChain LLM with HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=pipe,pipeline_kwargs={\"max_new_tokens\": 512},)\n",
    "\n",
    "# Chat Prompt Template\n",
    "system_message_template = \"you are a medical assistant classifying medical notes. List all the medications in the note in the prompt, only output them in JSON.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_message_template)\n",
    "\n",
    "human_message_template = \"Medical Note: {note}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_message_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# Create LLMChain\n",
    "medication_chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
    "\n",
    "def extract_notes(note):\n",
    "    medications = medication_chain.run(note=note).strip()\n",
    "    print(\"Raw LLM Output:\", medications)  # Print raw output\n",
    "    return medications\n",
    "        \n",
    "\n",
    "# Apply the extraction function to the DataFrame\n",
    "df['medications'] = df['note_clean'].apply(extract_notes)\n",
    "\n",
    "display(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MR</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>note</th>\n",
       "      <th>json_notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1234</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>58</td>\n",
       "      <td>male</td>\n",
       "      <td>Arrived for a follow-up appointment complainin...</td>\n",
       "      <td>{'disease': 'Type 2 Diabetes (T2D), hypertensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5678</td>\n",
       "      <td>Linda Green</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>Chief Complaint: Persistent headaches and ting...</td>\n",
       "      <td>{'disease': 'Type 2 Diabetes', 'symptoms': 'Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9102</td>\n",
       "      <td>Michael Brown</td>\n",
       "      <td>62</td>\n",
       "      <td>male</td>\n",
       "      <td>Follow-up for hypertension and Type 2 Diabetes...</td>\n",
       "      <td>{'disease': 'Hypertension and Type 2 Diabetes'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3344</td>\n",
       "      <td>Sarah Johnson</td>\n",
       "      <td>50</td>\n",
       "      <td>female</td>\n",
       "      <td>Complaint: Frequent urination, increased thirs...</td>\n",
       "      <td>{'disease': 'Type 2 Diabetes', 'symptoms': 'Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2211</td>\n",
       "      <td>Carlos Ramirez</td>\n",
       "      <td>55</td>\n",
       "      <td>male</td>\n",
       "      <td>Presenting with ongoing fatigue and left knee ...</td>\n",
       "      <td>{'disease': 'Type 2 Diabetes, Hypertension', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    MR            Name  Age   Gender  \\\n",
       "0           0  1234      John Smith   58     male   \n",
       "1           1  5678     Linda Green   45   female   \n",
       "2           2  9102   Michael Brown   62     male   \n",
       "3           3  3344   Sarah Johnson   50   female   \n",
       "4           4  2211  Carlos Ramirez   55     male   \n",
       "\n",
       "                                                note  \\\n",
       "0  Arrived for a follow-up appointment complainin...   \n",
       "1  Chief Complaint: Persistent headaches and ting...   \n",
       "2  Follow-up for hypertension and Type 2 Diabetes...   \n",
       "3  Complaint: Frequent urination, increased thirs...   \n",
       "4  Presenting with ongoing fatigue and left knee ...   \n",
       "\n",
       "                                          json_notes  \n",
       "0  {'disease': 'Type 2 Diabetes (T2D), hypertensi...  \n",
       "1  {'disease': 'Type 2 Diabetes', 'symptoms': 'Pe...  \n",
       "2  {'disease': 'Hypertension and Type 2 Diabetes'...  \n",
       "3  {'disease': 'Type 2 Diabetes', 'symptoms': 'Fr...  \n",
       "4  {'disease': 'Type 2 Diabetes, Hypertension', '...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Chat GPT\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import openai\n",
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "\n",
    "df_gpt = pd.read_csv(\"checkpoint1.csv\")\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_ORG_ID = os.getenv(\"OPENAI_ORG_ID\")   \n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# Load schema for the LLM output\n",
    "response_schemas = []\n",
    "\n",
    "for i in json_schema:\n",
    "    response_schemas.append(ResponseSchema(name=i[0], description=i[1]))\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# Prompt Template\n",
    "prompt_template = \"\"\"\n",
    "Extract the following information from the text and return it as a JSON object:\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Create Runnable Sequence\n",
    "note_chain = prompt | llm | output_parser\n",
    "\n",
    "def extract_notes(note):\n",
    "    try:\n",
    "        json_notes = note_chain.invoke({\"text\": note})\n",
    "        # print(\"Extracted Info:\", json_notes)\n",
    "        return json_notes\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting information: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the extraction function to the DataFrame\n",
    "df_gpt['json_notes'] = json.dumps(df['note'].apply(extract_notes))\n",
    "\n",
    "df_gpt.to_csv(\"checkpoint_chatGPT.csv\", index=True)\n",
    "display(df_gpt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MR</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>note</th>\n",
       "      <th>json_notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1234</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>58</td>\n",
       "      <td>male</td>\n",
       "      <td>Arrived for a follow-up appointment complainin...</td>\n",
       "      <td>{'disease': 'Type 2 Diabetes (T2D), hypertensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5678</td>\n",
       "      <td>Linda Green</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>Chief Complaint: Persistent headaches and ting...</td>\n",
       "      <td>{'disease': 'Type 2 Diabetes', 'symptoms': 'Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9102</td>\n",
       "      <td>Michael Brown</td>\n",
       "      <td>62</td>\n",
       "      <td>male</td>\n",
       "      <td>Follow-up for hypertension and Type 2 Diabetes...</td>\n",
       "      <td>{'disease': 'Hypertension and Type 2 Diabetes'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3344</td>\n",
       "      <td>Sarah Johnson</td>\n",
       "      <td>50</td>\n",
       "      <td>female</td>\n",
       "      <td>Complaint: Frequent urination, increased thirs...</td>\n",
       "      <td>{'disease': 'Type 2 Diabetes', 'symptoms': 'Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2211</td>\n",
       "      <td>Carlos Ramirez</td>\n",
       "      <td>55</td>\n",
       "      <td>male</td>\n",
       "      <td>Presenting with ongoing fatigue and left knee ...</td>\n",
       "      <td>{'disease': 'Type 2 Diabetes, Hypertension', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0    MR            Name  Age   Gender  \\\n",
       "0             0           0  1234      John Smith   58     male   \n",
       "1             1           1  5678     Linda Green   45   female   \n",
       "2             2           2  9102   Michael Brown   62     male   \n",
       "3             3           3  3344   Sarah Johnson   50   female   \n",
       "4             4           4  2211  Carlos Ramirez   55     male   \n",
       "\n",
       "                                                note  \\\n",
       "0  Arrived for a follow-up appointment complainin...   \n",
       "1  Chief Complaint: Persistent headaches and ting...   \n",
       "2  Follow-up for hypertension and Type 2 Diabetes...   \n",
       "3  Complaint: Frequent urination, increased thirs...   \n",
       "4  Presenting with ongoing fatigue and left knee ...   \n",
       "\n",
       "                                          json_notes  \n",
       "0  {'disease': 'Type 2 Diabetes (T2D), hypertensi...  \n",
       "1  {'disease': 'Type 2 Diabetes', 'symptoms': 'Pe...  \n",
       "2  {'disease': 'Hypertension and Type 2 Diabetes'...  \n",
       "3  {'disease': 'Type 2 Diabetes', 'symptoms': 'Fr...  \n",
       "4  {'disease': 'Type 2 Diabetes, Hypertension', '...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disease', 'symptoms', 'lab_results', 'current_medication', 'current_dosage', 'current_frequency', 'prescribed_medication', 'prescribed_dosage', 'prescribed_frequency']\n",
      "{'disease': 'Type 2 Diabetes (T2D), hypertension', 'symptoms': 'ongoing fatigue, occasional blurred vision, mild numbness in feet', 'lab_results': 'elevated A1C of 8.7%', 'current_medication': 'Metformin', 'current_dosage': '500 mg', 'current_frequency': 'BID', 'prescribed_medication': 'insulin', 'prescribed_dosage': 'adjust dosage if glucose remains high', 'prescribed_frequency': 'occasionally'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (json.JSONDecodeError, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m     23\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pd.Series(empties, index=fields) \u001b[38;5;66;03m#handle errors\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mdf_gpt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m]\u001b[49m = df_gpt[\u001b[33m'\u001b[39m\u001b[33mjson_notes\u001b[39m\u001b[33m'\u001b[39m].apply(extract_json)\n\u001b[32m     27\u001b[39m df_gpt.to_csv(\u001b[33m\"\u001b[39m\u001b[33mcheckpoint_chatGPT2.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     28\u001b[39m display(df_gpt.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/CH/CHvenv/lib/python3.12/site-packages/pandas/core/frame.py:4299\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4297\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_frame(key, value)\n\u001b[32m   4298\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np.ndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[32m-> \u001b[39m\u001b[32m4299\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4300\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[32m   4301\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_item_frame_value(key, value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/CH/CHvenv/lib/python3.12/site-packages/pandas/core/frame.py:4341\u001b[39m, in \u001b[36mDataFrame._setitem_array\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4337\u001b[39m     \u001b[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n\u001b[32m   4338\u001b[39m     \u001b[38;5;66;03m#  never try to overwrite values inplace\u001b[39;00m\n\u001b[32m   4340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[32m-> \u001b[39m\u001b[32m4341\u001b[39m         \u001b[43mcheck_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4342\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value.columns):\n\u001b[32m   4343\u001b[39m             \u001b[38;5;28mself\u001b[39m[k1] = value[k2]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/CH/CHvenv/lib/python3.12/site-packages/pandas/core/indexers/utils.py:390\u001b[39m, in \u001b[36mcheck_key_length\u001b[39m\u001b[34m(columns, key, value)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m columns.is_unique:\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value.columns) != \u001b[38;5;28mlen\u001b[39m(key):\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mColumns must be same length as key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    392\u001b[39m     \u001b[38;5;66;03m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns.get_indexer_non_unique(key)[\u001b[32m0\u001b[39m]) != \u001b[38;5;28mlen\u001b[39m(value.columns):\n",
      "\u001b[31mValueError\u001b[39m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "df_gpt = pd.read_csv(\"checkpoint_chatGPT.csv\")\n",
    "\n",
    "try:\n",
    "    df_gpt.drop(columns=fields, inplace=True)\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "display(df_gpt.head())\n",
    "\n",
    "print(fields)\n",
    "print(df_gpt[\"json_notes\"][0])  \n",
    "\n",
    "# Function to parse JSON and extract values\n",
    "def extract_json(json_string):\n",
    "    empties = {field: None for field in fields}\n",
    "    try:\n",
    "        pds = pd.Series(\"{'disease': 'Type 2 Diabetes (T2D), hypertension', 'symptoms': 'ongoing fatigue, occasional blurred vision, mild numbness in feet', 'lab_results': 'elevated A1C of 8.7%', 'current_medication': 'Metformin', 'current_dosage': '500 mg', 'current_frequency': 'BID', 'prescribed_medication': 'insulin', 'prescribed_dosage': 'adjust dosage if glucose remains high', 'prescribed_frequency': 'occasionally'}\")  # Convert JSON string to dict\n",
    "        return pds\n",
    "        #return pd.Series(json_string)  # Convert dict to Series\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return pd.Series(empties, index=fields) #handle errors\n",
    "\n",
    "df_gpt[fields] = df_gpt['json_notes'].apply(extract_json)\n",
    "\n",
    "df_gpt.to_csv(\"checkpoint_chatGPT2.csv\", index=True)\n",
    "display(df_gpt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{  \"medications\": [    {      \"name\": \"Metformin\",      \"dose\": \"500 mg\",      \"frequency\": \"BID\"    },    {      \"name\": \"Insulin\",      \"dose\": \"occasional\",      \"frequency\": \"as needed\"    },    {      \"name\": \"Lisinopril\",      \"dose\": \"20 mg\",      \"frequency\": \"daily\"    }  ]}\n",
      "{  \"medications\": [    \"Metformin 500 mg BID\",    \"Atorvastatin 10 mg daily\"  ]}\n",
      "{  \"medications\": [    \"Metformin 1000 mg daily\",    \"Lisinopril 20 mg daily\",    \"Multivitamin (brand unknown)\"  ]}\n",
      "{  \"medications\": [    \"Glipizide 5 mg daily\",    \"Simvastatin 20 mg daily\"  ]}\n",
      "{  \"medications\": [    \"Metformin 500 mg BID\",    \"Jardiance 10 mg daily\",    \"Losartan 50 mg daily\"  ]}\n",
      "{  \"medications\": [    \"Metformin 500 mg daily\"  ]}\n",
      "{  \"medications\": [    \"Metformin 500 mg BID\",    \"Insulin glargine (10 units nightly)\",    \"Amlodipine 5 mg daily\"  ]}\n",
      "{  \"medications\": [    {      \"name\": \"Metformin\",      \"dose\": \"500 mg\",      \"frequency\": \"once daily\"    }  ]}\n",
      "{  \"medications\": [    \"Metformin 1000 mg BID\",    \"Rosuvastatin 10 mg daily\"  ]}\n",
      "{  \"medications\": [    {      \"name\": \"Sertraline\",      \"dose\": \"50 mg\",      \"frequency\": \"daily\"    },    {      \"name\": \"Insulin detemir\",      \"dose\": \"15 units\",      \"frequency\": \"twice daily\"    },    {      \"name\": \"Metformin\",      \"dose\": \"500 mg\",      \"frequency\": \"twice daily\"    }  ]}\n",
      "{  \"medications\": [    \"Metformin 1000 mg BID\",    \"Lisinopril 20 mg daily\",    \"Acetaminophen (occasionally)\"  ]}\n",
      "{  \"medications\": [    \"Metformin 500 mg BID\",    \"Glipizide 5 mg daily\"  ]}\n",
      "{  \"medications\": [    \"Metformin 1000 mg BID\",    \"Sitagliptin 100 mg daily\"  ]}\n",
      "{  \"medications\": [    \"Metformin 500 mg TID\",    \"Atorvastatin 20 mg daily\"  ]}\n",
      "{  \"medications\": [    \"Metformin 500 mg BID\"  ]}\n",
      "{  \"medications\": [    \"Metformin 1000 mg BID\",    \"Rosuvastatin 10 mg daily\"  ]}\n",
      "{  \"medications\": [    \"Metformin 500 mg\"  ]}\n",
      "{  \"medications\": [    \"Metformin 500 mg TID\",    \"Ibuprofen PRN\",    \"Lisinopril 10 mg daily\"  ]}\n",
      "{  \"medications\": [    \"Metformin 1000 mg BID\",    \"Empagliflozin 10 mg daily\"  ]}\n",
      "{  \"medications\": [    \"Metformin 500 mg BID\",    \"Furosemide 20 mg daily\",    \"Carvedilol 6.25 mg BID\"  ]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MR</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>note</th>\n",
       "      <th>medications2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arrived for a follow-up appointment complainin...</td>\n",
       "      <td>{  \"medications\": [    {      \"name\": \"Metform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5678</td>\n",
       "      <td>Linda Green</td>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>Chief Complaint: Persistent headaches and ting...</td>\n",
       "      <td>{  \"medications\": [    \"Metformin 500 mg BID\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9102</td>\n",
       "      <td>Michael Brown</td>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>Follow-up for hypertension and Type 2 Diabetes...</td>\n",
       "      <td>{  \"medications\": [    \"Metformin 1000 mg dail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3344</td>\n",
       "      <td>Sarah Johnson</td>\n",
       "      <td>50</td>\n",
       "      <td>Female</td>\n",
       "      <td>Complaint: Frequent urination, increased thirs...</td>\n",
       "      <td>{  \"medications\": [    \"Glipizide 5 mg daily\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2211</td>\n",
       "      <td>Carlos Ramirez</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>Presenting with ongoing fatigue and left knee ...</td>\n",
       "      <td>{  \"medications\": [    \"Metformin 500 mg BID\",...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MR            Name  Age  Gender  \\\n",
       "0  1234      John Smith   58    Male   \n",
       "1  5678     Linda Green   45  Female   \n",
       "2  9102   Michael Brown   62    Male   \n",
       "3  3344   Sarah Johnson   50  Female   \n",
       "4  2211  Carlos Ramirez   55    Male   \n",
       "\n",
       "                                                note  \\\n",
       "0  Arrived for a follow-up appointment complainin...   \n",
       "1  Chief Complaint: Persistent headaches and ting...   \n",
       "2  Follow-up for hypertension and Type 2 Diabetes...   \n",
       "3  Complaint: Frequent urination, increased thirs...   \n",
       "4  Presenting with ongoing fatigue and left knee ...   \n",
       "\n",
       "                                        medications2  \n",
       "0  {  \"medications\": [    {      \"name\": \"Metform...  \n",
       "1  {  \"medications\": [    \"Metformin 500 mg BID\",...  \n",
       "2  {  \"medications\": [    \"Metformin 1000 mg dail...  \n",
       "3  {  \"medications\": [    \"Glipizide 5 mg daily\",...  \n",
       "4  {  \"medications\": [    \"Metformin 500 mg BID\",...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OLD\n",
    "\n",
    "# Request schema\n",
    "# class TextRequest(BaseModel):\n",
    "#     prompt: str\n",
    "#     max_new_tokens: int = 200\n",
    "#     temperature: float = 0.3\n",
    "#     top_p: float = 0.9\n",
    "\n",
    "\n",
    "def extract_medications_native(prompt):\n",
    "        #prompt = request.prompt \n",
    "        messages = [\n",
    "            {\"role\": \"system\",  \"content\": \"you are a medical assistant. List all the medications in the note, only output JSON\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) \n",
    " \n",
    "        # Tokenize the prompt (wrapped in a list)\n",
    "        model_inputs = tokenizer(text, return_tensors=\"pt\").to(my_local_model.device)\n",
    "\n",
    "        generated = my_local_model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=512,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.3,\n",
    "            top_p=0.9,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            num_beams=3,\n",
    "            stopping_criteria=stopping_criteria\n",
    "        )\n",
    "        outputs = tokenizer.decode(generated[0], skip_special_tokens=True) \n",
    "        \n",
    "        lines = outputs.split(\"\\n\")\n",
    "        \n",
    "        # find the line that reads \"assistant\"\n",
    "        for i, line in enumerate(lines):\n",
    "             if \"assistant\" == line:\n",
    "                 break\n",
    "        #return the next line\n",
    "        \n",
    "        #concatenate all lines after i+1\n",
    "        a = \"\"\n",
    "        for j in range(i+1, len(lines)):\n",
    "            a = a + lines[j]\n",
    "\n",
    "        # print (\"relevant row i = \", i+1)\n",
    "        print(a)\n",
    "        return a\n",
    "\n",
    "\n",
    "\n",
    "df['medications2'] = df['note'].apply(extract_medications_native)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{  \"medications\": [    \"Metformin 1000 mg BID\",    \"Rosuvastatin 10 mg daily\"  ]}\n"
     ]
    }
   ],
   "source": [
    "print(df['medications2'][15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CHvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
