{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extractors\n",
    "import regex as re\n",
    "\n",
    "# Fuzzy matching allows for 1 typo\n",
    "\n",
    "def extract_medical_record(text):\n",
    "    \"\"\"Extracts the medical record number from a given text using regex.\"\"\"\n",
    "    pattern = r\"(?:Medical\\s*Record|Medcal\\s*Record|Medicl\\s*Record|MR){e<=1}\\s*#\\s*:\\s*(\\S+)\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        # Check which group matched (1 or 2)\n",
    "        if match.group(1):\n",
    "            return match.group(1).strip()\n",
    "        else:\n",
    "            return match.group(2).strip()\n",
    "    else:\n",
    "        return None  # Or return \"NA\" if you prefer\n",
    "   \n",
    "def extract_name(text):\n",
    "    \"\"\"Extracts patient name from a given text using regex.\"\"\"\n",
    "    pattern = r\"(?:Patient){e<=1}:\\s*([^,]+)\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None  # Or return \"Unknown\" or \"NA\"\n",
    "\n",
    "def extract_age(text):\n",
    "    \"\"\"Extracts age from a given text using regex patterns.\"\"\"\n",
    "    age_patterns = [\n",
    "        r\"(\\d+)-(?:year|yeer|yer|yar){e<=1}-old\",   # Allow 1 typo in \"year\"\n",
    "        r\"(?:age|ag|aeg|gae){e<=1}\\s*(\\d+)\",        # Allow 1 typo in \"age\"\n",
    "        r\"(\\d+)\\s*(?:years?|yeers?|yrs?|yars?){e<=1}\\s*old\",  # Allow 1 typo in \"years\", \"yrs\"\n",
    "        r\"(\\d+)\\s*(?:years?|yeers?|yrs?|yars?){e<=1}\"         # Allow 1 typo in \"years\", \"yrs\"\n",
    "    ]\n",
    "\n",
    "    age = None\n",
    "\n",
    "    for pattern in age_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE) #added re.IGNORECASE to handle variations in case\n",
    "        if match:\n",
    "            try:\n",
    "                age = int(match.group(1))\n",
    "                break  # Stop after finding the first match\n",
    "            except ValueError:\n",
    "                # Handle cases where the extracted value is not a valid number\n",
    "                pass\n",
    "    return age\n",
    "\n",
    "def extract_gender(text):\n",
    "    \"\"\"Extracts gender from a given text using regex.\"\"\"\n",
    "    pattern = r\"\\b(male|female){e<=1}\\b\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).capitalize()  # Capitalize and return\n",
    "    else:\n",
    "        return \"Unknown\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MR</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>58</td>\n",
       "      <td>male</td>\n",
       "      <td>Arrived for a follow-up appointment complainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5678</td>\n",
       "      <td>Linda Green</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>Chief Complaint: Persistent headaches and ting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9102</td>\n",
       "      <td>Michael Brown</td>\n",
       "      <td>62</td>\n",
       "      <td>male</td>\n",
       "      <td>Follow-up for hypertension and Type 2 Diabetes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MR           Name  Age   Gender  \\\n",
       "0  1234     John Smith   58     male   \n",
       "1  5678    Linda Green   45   female   \n",
       "2  9102  Michael Brown   62     male   \n",
       "\n",
       "                                                note  \n",
       "0  Arrived for a follow-up appointment complainin...  \n",
       "1  Chief Complaint: Persistent headaches and ting...  \n",
       "2  Follow-up for hypertension and Type 2 Diabetes...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extract\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_excel(\"notes.xlsx\") \n",
    "\n",
    "# Extract\n",
    "df['MR']       = df['note'].apply(extract_medical_record)\n",
    "df[\"Name\"]     = df[\"note\"].apply(extract_name)\n",
    "df[\"Gender\"]   = df[\"note\"].apply(extract_gender)\n",
    "df['Age']      = df['note'].apply(extract_age)\n",
    "\n",
    "# Cleanup the note on the assumption \\n are in the right place (this shortens the prompt)\n",
    "df['note'] = df['note'].str.split(\"\\n\", expand=True, n=2).fillna(\"\")[2]\n",
    "\n",
    "# Note, remove new lines\n",
    "df['note'] = df['note'].str.replace(\"\\n\", \" \")\n",
    "\n",
    "# Sort the coulmns\n",
    "df = df[[\"MR\",\"Name\", \"Age\", \"Gender\", \"note\"]]\n",
    "\n",
    "display(df.head(3))\n",
    "\n",
    "df.to_csv(\"checkpoint1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the medical record JSON\n",
    "\n",
    "json_schema = [\n",
    "    [\"disease\", \"The disease the patient is suffering from\"],\n",
    "    [\"symptoms\", \"The symptoms the patient is experiencing\"],\n",
    "    [\"lab_results\", \"The results of the lab tests\"],\n",
    "    [\"current_medication\", \"The medication the patient is currently taking\"],\n",
    "    [\"current_dosage\", \"The dosage of the current medication, just the dosage, not the name\"],\n",
    "    [\"current_frequency\", \"The frequency of  current medication, just the frequency, not the name\"],\n",
    "    [\"prescribed_medication\", \"The medication prescribed\"],\n",
    "    [\"prescribed_dosage\", \"The dosage of the prescribed medication\"],\n",
    "    [\"prescribed_frequency\", \"The frequency of the prescribed medication\"],\n",
    "]\n",
    "\n",
    "fields= []\n",
    "decritpion = []\n",
    "for x in json_schema:\n",
    "    fields.append(x[0])\n",
    "    decritpion.append(x[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRY_LOCAL=True\n",
      "env: GPU_ID=1\n",
      "Total Memory: 23.7 GB\n",
      "We can run the model locally on gpu  1\n",
      "You need 20Gb of VRAM, you have 23.7 Gb\n",
      "env: MODEL=Local\n"
     ]
    }
   ],
   "source": [
    "# Check if you can run the model locally\n",
    "import torch\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "%env TRY_LOCAL=False\n",
    "\n",
    "if os.getenv(\"TRY_LOCAL\") != \"True\":\n",
    "    print(\"If you want to try to run your LLM locally, set TRY_LOCAL to True.\")\n",
    "    print(\"Let's use ChatGPT\")\n",
    "    %env MODEL=ChatGPT\n",
    "elif torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    gpu_id = num_gpus - 1 # Arbitrarity run the model on the last GPU, presumably video is on card 0\n",
    "    %env GPU_ID=$gpu_id\n",
    "    total_memory = torch.cuda.get_device_properties(gpu_id).total_memory \n",
    "    print(f\"Total Memory: {total_memory /(1024**3):.1f} GB\")\n",
    "    if total_memory/(1024**3) > 20:\n",
    "        print(\"We can run the model locally on gpu \", gpu_id)\n",
    "        print(f\"You need 20Gb of VRAM, you have {total_memory / (1024**3):.1f} Gb\")\n",
    "        %env MODEL=Local\n",
    "    else:\n",
    "        print(\"Not enough memory to run the model\")\n",
    "        print(f\"You need 20Gb of VRAM, you have {total_memory / (1024**3):.1f} Gb\")\n",
    "        %env MODEL=ChatGPT\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "    print(\"Let's use ChatGPT\")\n",
    "    %env MODEL=ChatGPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mINFO\u001b[0m  ENV: Auto setting PYTORCH_CUDA_ALLOC_CONF='expandable_segments:True' for memory saving.\n",
      "\u001b[32mINFO\u001b[0m  ENV: Auto setting CUDA_DEVICE_ORDER=PCI_BUS_ID for correctness.          \n",
      "GPU memory cleared.\n",
      "Loading Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4 on cuda:1\n",
      "Using custom cache directory /mnt/hd1\n",
      "Huggingface key is valid. Logged as: lookino \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m   Kernel: Auto-selection: adding candidate `MarlinQuantLinear`            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9904711263404422aa2f9fc862c5e258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load LLM on local GPU\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "import gptqmodel\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig,StoppingCriteria, StoppingCriteriaList, pipeline\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if os.environ.get(\"MODEL\", \"\") == 'Local':\n",
    "\n",
    "    torch.cuda.empty_cache()  # Clear cached memory\n",
    "    gc.collect() \n",
    "    print(\"GPU memory cleared.\")\n",
    "        \n",
    "    # model_id = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "    model_id = \"Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4\"\n",
    "\n",
    "    # Set the device defined in previous cell\n",
    "    device_s = \"cuda:\" + os.environ.get(\"GPU_ID\", \"\")\n",
    "    device = device_s if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    print(\"Loading \" + model_id + \" on \" + device)  \n",
    "\n",
    "    directory = \"/mnt/hd1\"\n",
    "    if os.path.isdir(directory):\n",
    "        print(\"Using custom cache directory \" + directory)\n",
    "        custom_cache_dir = \"/mnt/hd1\"\n",
    "    else:\n",
    "        custom_cache_dir = \"/tmp\"\n",
    "\n",
    "    #Hugging face API KEY, check it's there and it is valid\n",
    "    HF_API_KEY = os.getenv(\"HF_API_KEY\")\n",
    "    token = HF_API_KEY\n",
    "\n",
    "    if token is None:\n",
    "        print(\"No Huggingface API key found\")\n",
    "    else:\n",
    "        try:\n",
    "            api = HfApi(token=token)\n",
    "            user_info = api.whoami()\n",
    "            print(f\"Huggingface key is valid. Logged as: {user_info['name']} \")\n",
    "        except Exception as e:\n",
    "            print(f\"Invalid API key: {e}\")\n",
    "\n",
    "        # Load the tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id, token=token)\n",
    "\n",
    "        # Load the model \n",
    "        my_local_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        token=token,\n",
    "        cache_dir=custom_cache_dir,    \n",
    "        device_map=device,              \n",
    "        torch_dtype=torch.bfloat16,           \n",
    "        )\n",
    "else:\n",
    "    print(\"This section is disabled, as we are using ChatGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:1\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MR</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>note</th>\n",
       "      <th>json_note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1234</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>58</td>\n",
       "      <td>male</td>\n",
       "      <td>Arrived for a follow-up appointment complainin...</td>\n",
       "      <td>{\\n    \"disease\": \"Type 2 Diabetes\",\\n    \"sym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5678</td>\n",
       "      <td>Linda Green</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>Chief Complaint: Persistent headaches and ting...</td>\n",
       "      <td>{\\n    \"disease\": \"Type 2 Diabetes\",\\n    \"sym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9102</td>\n",
       "      <td>Michael Brown</td>\n",
       "      <td>62</td>\n",
       "      <td>male</td>\n",
       "      <td>Follow-up for hypertension and Type 2 Diabetes...</td>\n",
       "      <td>{\\n    \"disease\": \"hypertension and Type 2 Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3344</td>\n",
       "      <td>Sarah Johnson</td>\n",
       "      <td>50</td>\n",
       "      <td>female</td>\n",
       "      <td>Complaint: Frequent urination, increased thirs...</td>\n",
       "      <td>{\\n    \"disease\": \"Type 2 Diabetes\",\\n    \"sym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2211</td>\n",
       "      <td>Carlos Ramirez</td>\n",
       "      <td>55</td>\n",
       "      <td>male</td>\n",
       "      <td>Presenting with ongoing fatigue and left knee ...</td>\n",
       "      <td>{\\n    \"disease\": \"Type 2 Diabetes, Hypertensi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    MR            Name  Age   Gender  \\\n",
       "0           0  1234      John Smith   58     male   \n",
       "1           1  5678     Linda Green   45   female   \n",
       "2           2  9102   Michael Brown   62     male   \n",
       "3           3  3344   Sarah Johnson   50   female   \n",
       "4           4  2211  Carlos Ramirez   55     male   \n",
       "\n",
       "                                                note  \\\n",
       "0  Arrived for a follow-up appointment complainin...   \n",
       "1  Chief Complaint: Persistent headaches and ting...   \n",
       "2  Follow-up for hypertension and Type 2 Diabetes...   \n",
       "3  Complaint: Frequent urination, increased thirs...   \n",
       "4  Presenting with ongoing fatigue and left knee ...   \n",
       "\n",
       "                                           json_note  \n",
       "0  {\\n    \"disease\": \"Type 2 Diabetes\",\\n    \"sym...  \n",
       "1  {\\n    \"disease\": \"Type 2 Diabetes\",\\n    \"sym...  \n",
       "2  {\\n    \"disease\": \"hypertension and Type 2 Dia...  \n",
       "3  {\\n    \"disease\": \"Type 2 Diabetes\",\\n    \"sym...  \n",
       "4  {\\n    \"disease\": \"Type 2 Diabetes, Hypertensi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "df_local = pd.read_csv(\"checkpoint1.csv\")\n",
    "\n",
    "class StopAtEndOfJson(StoppingCriteria):\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        # Stop if a period followed by a space appears\n",
    "        return tokenizer.decode(input_ids[0]).endswith(\"\\\"\\n}\\n````\")\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopAtEndOfJson()])\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=my_local_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=1024,\n",
    "    temperature=0.3,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Initialize LangChain LLM with HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "\n",
    "# Load schema for the LLM output\n",
    "response_schemas = []\n",
    "\n",
    "for i in json_schema:\n",
    "    response_schemas.append(ResponseSchema(name=i[0], description=i[1]))\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# Prompt Template\n",
    "prompt_template = \"\"\"\n",
    "Extract the following information from the text and return it as a JSON object:\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "def preprocess_llm_output(llm_output: str) -> str:\n",
    "    \"\"\"Preprocesses the LLM output to extract the JSON block.\"\"\"\n",
    "    \n",
    "    llm_output = llm_output.split(\"JSON:\\n```json\", 1)[1]\n",
    "    llm_output = llm_output.split(\"}\\n```\", 1)[0] + \"}\"\n",
    "    llm_output.strip()\n",
    "    return llm_output\n",
    "    #print(\"LLM Output:\", llm_output)\n",
    "\n",
    "\n",
    "note_chain = prompt | llm | preprocess_llm_output | output_parser\n",
    "\n",
    "# Create Runnable Sequence\n",
    "\n",
    "def extract_notes(note):\n",
    "    try:\n",
    "        my_output = note_chain.invoke({\"text\": note})   \n",
    "        json_note = json.dumps(my_output, indent=4)\n",
    "        return json_note\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting information: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the extraction function to the DataFrame\n",
    "df_local['json_note'] = df_local['note'].apply(extract_notes)\n",
    "\n",
    "df_local.to_csv(\"checkpoint_Qwen.csv\", index=True)\n",
    "display(df_local.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MR</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>note</th>\n",
       "      <th>json_note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1234</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>58</td>\n",
       "      <td>male</td>\n",
       "      <td>Arrived for a follow-up appointment complainin...</td>\n",
       "      <td>{\"disease\": \"Type 2 Diabetes (T2D), hypertensi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5678</td>\n",
       "      <td>Linda Green</td>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>Chief Complaint: Persistent headaches and ting...</td>\n",
       "      <td>{\"disease\": \"Type 2 Diabetes\", \"symptoms\": \"Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9102</td>\n",
       "      <td>Michael Brown</td>\n",
       "      <td>62</td>\n",
       "      <td>male</td>\n",
       "      <td>Follow-up for hypertension and Type 2 Diabetes...</td>\n",
       "      <td>{\"disease\": \"Hypertension and Type 2 Diabetes\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3344</td>\n",
       "      <td>Sarah Johnson</td>\n",
       "      <td>50</td>\n",
       "      <td>female</td>\n",
       "      <td>Complaint: Frequent urination, increased thirs...</td>\n",
       "      <td>{\"disease\": \"Type 2 Diabetes\", \"symptoms\": \"Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2211</td>\n",
       "      <td>Carlos Ramirez</td>\n",
       "      <td>55</td>\n",
       "      <td>male</td>\n",
       "      <td>Presenting with ongoing fatigue and left knee ...</td>\n",
       "      <td>{\"disease\": \"Type 2 Diabetes\", \"symptoms\": \"on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    MR            Name  Age   Gender  \\\n",
       "0           0  1234      John Smith   58     male   \n",
       "1           1  5678     Linda Green   45   female   \n",
       "2           2  9102   Michael Brown   62     male   \n",
       "3           3  3344   Sarah Johnson   50   female   \n",
       "4           4  2211  Carlos Ramirez   55     male   \n",
       "\n",
       "                                                note  \\\n",
       "0  Arrived for a follow-up appointment complainin...   \n",
       "1  Chief Complaint: Persistent headaches and ting...   \n",
       "2  Follow-up for hypertension and Type 2 Diabetes...   \n",
       "3  Complaint: Frequent urination, increased thirs...   \n",
       "4  Presenting with ongoing fatigue and left knee ...   \n",
       "\n",
       "                                           json_note  \n",
       "0  {\"disease\": \"Type 2 Diabetes (T2D), hypertensi...  \n",
       "1  {\"disease\": \"Type 2 Diabetes\", \"symptoms\": \"Pe...  \n",
       "2  {\"disease\": \"Hypertension and Type 2 Diabetes\"...  \n",
       "3  {\"disease\": \"Type 2 Diabetes\", \"symptoms\": \"Fr...  \n",
       "4  {\"disease\": \"Type 2 Diabetes\", \"symptoms\": \"on...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Chat GPT\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "\n",
    "df_gpt = pd.read_csv(\"checkpoint1.csv\")\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_ORG_ID = os.getenv(\"OPENAI_ORG_ID\")   \n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# Load schema for the LLM output\n",
    "response_schemas = []\n",
    "\n",
    "for i in json_schema:\n",
    "    response_schemas.append(ResponseSchema(name=i[0], description=i[1]))\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# Prompt Template\n",
    "prompt_template = \"\"\"\n",
    "Extract the following information from the text and return it as a JSON object:\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "JSON:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Create Runnable Sequence\n",
    "note_chain = prompt | llm | output_parser\n",
    "\n",
    "def extract_notes(note):\n",
    "    try:\n",
    "        json_note = json.dumps(note_chain.invoke({\"text\": note}))\n",
    "        return json_note\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting information: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the extraction function to the DataFrame\n",
    "df_gpt['json_note'] = df['note'].apply(extract_notes)\n",
    "\n",
    "df_gpt.to_csv(\"checkpoint_chatGPT.csv\", index=False)\n",
    "display(df_gpt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the JSON fields from the JSON notes\n",
    "\n",
    "def extract_json(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    try:\n",
    "        df.drop(columns=fields, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    # Function to parse JSON and extract values\n",
    "    def extract_json(json_string):\n",
    "        empties = {field: None for field in fields}\n",
    "        try:\n",
    "            return pd.Series(json.loads(json_string))\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            return pd.Series(empties, index=fields) #handle errors\n",
    "\n",
    "    df[fields] = df['json_note'].apply(extract_json)\n",
    "\n",
    "    df.drop(columns=[\"json_note\"], inplace=True)\n",
    "\n",
    "    new_filename = filename.replace(\".csv\", \"_2.csv\")\n",
    "\n",
    "    df.to_csv(new_filename, index=False)\n",
    "\n",
    "\n",
    "# Run it on both\n",
    "extract_json(\"checkpoint_chatGPT.csv\")\n",
    "extract_json(\"checkpoint_Qwen.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CHvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
